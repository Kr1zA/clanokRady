{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9647405785958870994\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14200583867928706899\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 415968432726494645\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5547918624\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15557676650584363286\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:83:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import predspracovanie\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pickle\n",
    "\n",
    "import copy\n",
    "\n",
    "import tensorflow.keras.backend as backend\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"GPU\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [\n",
    "    '30m-item56', \n",
    "         '30m-item57', '30m-item58', '30m-item59', '30m-item61', '30m-item62', '30m-item66', '30m-item67', '30m-item69', '30m-item71', '30m-item72', '30m-item73', '30m-item75',\n",
    "    '30m-item76', \n",
    "    '30m-item77'\n",
    "        ]\n",
    "df = pickle.load( open( \"/home/richard_stana/programing/clanok/data/picklnute/30min.p\", \"rb\" ) )\n",
    "# df = predspracovanie.make_dataset(df)\n",
    "df = df.drop([\"30m-item60\", \"30m-item63\", \"30m-item64\", \"30m-item65\", \"30m-item68\", \"30m-item70\", \"30m-item74\"], axis=1)\n",
    "# df = df[actual_item]\n",
    "# predspracovanie.draw(df, datum_alebo_cisla=\"cislo\", y1_orig=df[actual_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = df[76:44000]\n",
    "# val_df = df[44001:46655]\n",
    "# test_df = df[46800:52389]\n",
    "train_df = df[27:15549]\n",
    "train1_df = df[15602:17160]\n",
    "val_df = df[17160-144-1:17460]\n",
    "# test_df = df[46800:52389]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_orig = train_df.copy()\n",
    "train_df = predspracovanie.create_log_difference(train_df)\n",
    "train1_df_orig = train1_df.copy()\n",
    "train1_df = predspracovanie.create_log_difference(train1_df)\n",
    "val_df_orig = val_df.copy()\n",
    "val_df = predspracovanie.create_log_difference(val_df)\n",
    "# test_df_orig = test_df.copy()\n",
    "# test_df = predspracovanie.create_log_difference(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 144\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(projekt, model, nazov_modelu, train_x, train_y, train_x1, train_y1, val_x, val_y, compile=False, epochs=200):\n",
    "    wandb.init(project=projekt, name=nazov_modelu + str(n_outputs))\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models_clanok/\" + nazov_modelu + \"future\" + str(n_outputs) + \".hdf5\",\n",
    "        #     save_weights_only=True,\n",
    "        monitor='val_mae',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "    model_checkpoint_callback1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models_clanok/\" + nazov_modelu + \"future\" + str(n_outputs) + \"1.hdf5\",\n",
    "        #     save_weights_only=True,\n",
    "        monitor='val_mae',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    if compile:\n",
    "        model.compile(loss='mse',\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics='mae')\n",
    "\n",
    "    history = model.fit(x=np.array(train_x).reshape((-1,n_inputs,1)),\n",
    "                      y=np.array(train_y).reshape((-1,n_outputs)),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(np.array(val_x).reshape((-1,n_inputs,1)), np.array(val_y).reshape((-1,n_outputs))),\n",
    "                      batch_size=128,\n",
    "                      callbacks=[model_checkpoint_callback, \n",
    "                                     WandbCallback()\n",
    "                                ])\n",
    "    history = model.fit(x=np.array(train_x).reshape((-1,n_inputs,1)),\n",
    "                      y=np.array(train_y).reshape((-1,n_outputs)),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(np.array(val_x).reshape((-1,n_inputs,1)), np.array(val_y).reshape((-1,n_outputs))),\n",
    "                      batch_size=128,\n",
    "                      callbacks=[model_checkpoint_callback1, \n",
    "                                     WandbCallback()\n",
    "                                ])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"lstm_input\"\n",
    ")  \n",
    "lstm = layers.LSTM(512, return_sequences=True)(lstm_input)\n",
    "lstm = layers.LSTM(512, return_sequences=True)(lstm)\n",
    "lstm = layers.LSTM(512, return_sequences=False)(lstm)\n",
    "lstm_output = layers.Dense(units=n_outputs)(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = keras.Model(\n",
    "    inputs=[lstm_input],\n",
    "    outputs=[lstm_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"cnn_input\"\n",
    ")  \n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn_input)\n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn)\n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn)\n",
    "flat = layers.Flatten()(cnn)\n",
    "dense = layers.Dense(units=64, activation='relu')(flat)\n",
    "cnn_output = layers.Dense(units=n_outputs)(dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.Model(\n",
    "    inputs=[cnn_input],\n",
    "    outputs=[cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobra_cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"dobra_cnn_input\"\n",
    ")  \n",
    "dobra_cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn_input)\n",
    "dobra_cnn = layers.Conv1D(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn)\n",
    "dobra_cnn = layers.Conv1D(filters=64,\n",
    "                           kernel_size=(3,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn)\n",
    "dobra_flat = layers.Flatten()(dobra_cnn)\n",
    "dobra_dense = layers.Dense(units=64, activation='relu')(dobra_flat)\n",
    "dobra_cnn_output = layers.Dense(units=n_outputs)(dobra_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobra_model_cnn = keras.Model(\n",
    "    inputs=[dobra_cnn_input],\n",
    "    outputs=[dobra_cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dobra_cnn_input (InputLayer) [(None, 144, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 144, 256)          2048      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 144, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 144, 64)           24640     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 781,194\n",
      "Trainable params: 781,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dobra_model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_up_cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"down_up_cnn_input\"\n",
    ")  \n",
    "down_up_cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn_input)\n",
    "down_up_cnn = layers.Conv1D(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn)\n",
    "down_up_flat = layers.Flatten()(down_up_cnn)\n",
    "down_up_dense = layers.Dense(units=1, activation='sigmoid')(down_up_flat)\n",
    "down_up_dense = layers.Dense(units=144*64, input_dim=128)(down_up_dense)\n",
    "down_up_reshape = layers.Reshape((144, 64))(down_up_dense)\n",
    "down_up_cnn = layers.Conv1DTranspose(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_reshape)\n",
    "down_up_cnn = layers.Conv1DTranspose(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn)\n",
    "down_up_flat = layers.Flatten()(down_up_cnn)\n",
    "# down_up_dense = layers.Dense(units=64, activation='relu')(down_up_flat)\n",
    "down_up_cnn_output = layers.Dense(units=n_outputs)(down_up_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_up_model_cnn = keras.Model(\n",
    "    inputs=[down_up_cnn_input],\n",
    "    outputs=[down_up_cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "down_up_cnn_input (InputLaye [(None, 144, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 144, 256)          2048      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 144, 128)          163968    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 18433     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9216)              18432     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 144, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 144, 128)          41088     \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 144, 256)          229632    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                368650    \n",
      "=================================================================\n",
      "Total params: 842,251\n",
      "Trainable params: 842,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "down_up_model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lstm_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"lstm_input\"\n",
    ")  \n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm_input)\n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm)\n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm)\n",
    "by_lstm_output = layers.Dense(units=n_outputs)(by_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lstm_model = keras.Model(\n",
    "    inputs=[by_lstm_input],\n",
    "    outputs=[by_lstm_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"gru_input\"\n",
    ")  \n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru_input)\n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "simpleRRN = tf.keras.layers.SimpleRNN(128, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "gru_output = layers.Dense(units=n_outputs)(simpleRRN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = keras.Model(\n",
    "    inputs=[gru_input],\n",
    "    outputs=[gru_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"encoder_inputs\"\n",
    ")  \n",
    "encoder_l1 = layers.LSTM(512, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "decoder_inputs = layers.RepeatVector(n_outputs)(encoder_outputs1[0])\n",
    "decoder_l1 = layers.LSTM(512, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = layers.TimeDistributed(layers.Dense(1))(decoder_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 144, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 512), (None, 1052672     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 10, 512)      0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 10, 512)      2099200     repeat_vector[0][0]              \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 10, 1)        513         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,152,385\n",
      "Trainable params: 3,152,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_e1d1 = keras.Model(\n",
    "    inputs=[encoder_inputs],\n",
    "    outputs=[decoder_outputs1]\n",
    ")\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_input = keras.Input(\n",
    "    shape=(n_inputs), name=\"dense_input\"\n",
    ")  \n",
    "dense = layers.Dense(units=1024, activation='relu')(dense_input)\n",
    "dense = layers.Dense(units=512, activation='relu')(dense)\n",
    "dense = layers.Dense(units=256, activation='relu')(dense)\n",
    "dense = layers.Dense(units=128, activation='relu')(dense)\n",
    "dense_output = layers.Dense(units=n_outputs)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (InputLayer)     [(None, 144)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              148480    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 838,794\n",
      "Trainable params: 838,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense = keras.Model(\n",
    "    inputs=[dense_input],\n",
    "    outputs=[dense_output]\n",
    ")\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkriza\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lstm-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2jxja6kk\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2jxja6kk</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_224151-2jxja6kk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 18s 151ms/step - loss: 0.0269 - mae: 0.0695 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 17s 145ms/step - loss: 0.0266 - mae: 0.0696 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 17s 144ms/step - loss: 0.0267 - mae: 0.0703 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 17s 144ms/step - loss: 0.0254 - mae: 0.0705 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 17s 144ms/step - loss: 0.0243 - mae: 0.0711 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 18s 145ms/step - loss: 0.0214 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 18s 151ms/step - loss: 0.0209 - mae: 0.0685 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0221 - mae: 0.0694 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0207 - mae: 0.0682 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0204 - mae: 0.0681 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0202 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0202 - mae: 0.0683 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0197 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0194 - mae: 0.0681 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0191 - mae: 0.0679 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0188 - mae: 0.0678 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0188 - mae: 0.0677 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0188 - mae: 0.0676 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0188 - mae: 0.0675 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0187 - mae: 0.0674 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0187 - mae: 0.0673 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0187 - mae: 0.0674 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0186 - mae: 0.0673 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0198 - mae: 0.0698 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0196 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0188 - mae: 0.0677 - val_loss: 0.0053 - val_mae: 0.0535\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0186 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0537\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0185 - mae: 0.0671 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0185 - mae: 0.0671 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0184 - mae: 0.0670 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0184 - mae: 0.0670 - val_loss: 0.0053 - val_mae: 0.0534\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0186 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0184 - mae: 0.0670 - val_loss: 0.0053 - val_mae: 0.0536\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0185 - mae: 0.0670 - val_loss: 0.0053 - val_mae: 0.0535\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0184 - mae: 0.0669 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0183 - mae: 0.0669 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0183 - mae: 0.0668 - val_loss: 0.0053 - val_mae: 0.0535\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0184 - mae: 0.0670 - val_loss: 0.0053 - val_mae: 0.0534\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0186 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0536\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0185 - mae: 0.0670 - val_loss: 0.0053 - val_mae: 0.0534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2jxja6kk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27587<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_224151-2jxja6kk/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_224151-2jxja6kk/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.01849</td></tr><tr><td>mae</td><td>0.06697</td></tr><tr><td>val_loss</td><td>0.00531</td></tr><tr><td>val_mae</td><td>0.05335</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>757</td></tr><tr><td>_timestamp</td><td>1611528868</td></tr><tr><td>best_val_loss</td><td>0.00529</td></tr><tr><td>best_epoch</td><td>10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>███▇▆▄▃▄▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>▅▆▇▇█▅▄▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▆▄▂▂▁▁▁▁▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_loss</td><td>▆▅▅█▆▆▅▄▅▄█▇▆▆▃▄▄▄▅▅▃▄▃▄▅▂▃▃▂▄▁▄▂▂▄▄▂▂▃▂</td></tr><tr><td>val_mae</td><td>▇▅▅█▇▇▇▆▆▆█▇▆▆▄▅▄▄▅▄▃▄▃▄▆▂▃▃▃▄▁▃▂▂▅▃▁▁▂▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lstm-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2jxja6kk\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2jxja6kk</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2jxja6kk). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2baeo2pq\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2baeo2pq</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225428-2baeo2pq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.0270 - mae: 0.0692 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.05441s - loss: 0.0301 - mae: 0.06 - ETA: 1s - loss: 0.0301 - mae: 0.069 - ETA: 1s - loss: 0.0304 - mae: 0.069 - ETA: 1s - loss: 0.0296 - mae: 0.069 - ETA: 1s - loss: 0.0288 - mae: 0.069 - ETA: 1s - loss: 0.0286 - mae: 0.069 - ETA: 1s - loss: 0.0285 - mae: 0.069 - ETA: 1s - loss: 0.0278 - mae: 0.06 - ETA: 0s - loss: 0.0279 - mae: 0.069 - ETA: 0s - loss: 0.0272 - ma - ETA: 0s - loss: 0.0267 - mae: \n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544 loss: 0.0297 - mae: 0.069 - ETA: 0s - loss: 0.0291 - mae: 0.0 - ETA: 0s - loss: 0.0284 - m\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.05441\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2baeo2pq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30240<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225428-2baeo2pq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225428-2baeo2pq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02699</td></tr><tr><td>mae</td><td>0.06895</td></tr><tr><td>val_loss</td><td>0.00545</td></tr><tr><td>val_mae</td><td>0.0544</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>118</td></tr><tr><td>_timestamp</td><td>1611528989</td></tr><tr><td>best_val_loss</td><td>0.00544</td></tr><tr><td>best_epoch</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▁▂▂▂▁▂▂▁▁▂▁▁</td></tr><tr><td>mae</td><td>█▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▂▂▁▂▁▂▂▂▁▂▂▁▂▁▂▁▁▂▁▂▁▂▂▁</td></tr><tr><td>val_loss</td><td>▁▃▂▂▃▃▂▁▅▅▂▄▂▃▄▃▃▂▄▂▂▅▃▃█▃▄▃▃▃▅▄▅▄▅▂▆▂▃▅</td></tr><tr><td>val_mae</td><td>▂▄▂▂▄▃▂▁▆▅▂▃▂▄▅▃▃▃▄▂▂▅▄▄█▃▄▃▃▄▆▄▆▄▅▃▇▃▃▅</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2baeo2pq\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2baeo2pq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2baeo2pq). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dobra_cnn-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2pe2ghzy\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2pe2ghzy</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225629-2pe2ghzy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0262 - mae: 0.0696 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0241 - mae: 0.0695 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0224 - mae: 0.0692 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0217 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0209 - mae: 0.0687 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0204 - mae: 0.0685 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0201 - mae: 0.0683 - val_loss: 0.0057 - val_mae: 0.0551\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0198 - mae: 0.0683 - val_loss: 0.0056 - val_mae: 0.0549\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0197 - mae: 0.0682 - val_loss: 0.0057 - val_mae: 0.0552\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0197 - mae: 0.0683 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0201 - mae: 0.0686 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0194 - mae: 0.0682 - val_loss: 0.0056 - val_mae: 0.0549\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0192 - mae: 0.0681 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0194 - mae: 0.0681 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0192 - mae: 0.0681 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0189 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0190 - mae: 0.0679 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0189 - mae: 0.0679 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0189 - mae: 0.0679 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0189 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0188 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0677 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0187 - mae: 0.0677 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0677 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0677 - val_loss: 0.0056 - val_mae: 0.0551\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0189 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0188 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0676 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0677 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0186 - mae: 0.0675 - val_loss: 0.0055 - val_mae: 0.0550\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0676 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0186 - mae: 0.0676 - val_loss: 0.0055 - val_mae: 0.0550\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0186 - mae: 0.0676 - val_loss: 0.0056 - val_mae: 0.0551\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - ETA: 0s - loss: 0.0188 - mae: 0.067 - 1s 10ms/step - loss: 0.0187 - mae: 0.0676 - val_loss: 0.0056 - val_mae: 0.0551\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0188 - mae: 0.0677 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0197 - mae: 0.0681 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0188 - mae: 0.0678 - val_loss: 0.0056 - val_mae: 0.0550\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0187 - mae: 0.0676 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0186 - mae: 0.0675 - val_loss: 0.0056 - val_mae: 0.0551\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2pe2ghzy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30767<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225629-2pe2ghzy/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225629-2pe2ghzy/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.01857</td></tr><tr><td>mae</td><td>0.06749</td></tr><tr><td>val_loss</td><td>0.00557</td></tr><tr><td>val_mae</td><td>0.05506</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>55</td></tr><tr><td>_timestamp</td><td>1611529047</td></tr><tr><td>best_val_loss</td><td>0.00544</td></tr><tr><td>best_epoch</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▇▆▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>mae</td><td>▆█▇▇▆▅▄▄▄▃▄▅▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▃▂▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▂▁▄▇▆█▁▂▄▃▁▃▂▃▂▂▃▂▄▂▂▅▃▂▃▅▄▄▄▄▅▅▃▄▃▄</td></tr><tr><td>val_mae</td><td>▁▁▁▁▁▁▄▇▅█▁▃▅▃▂▃▃▄▄▄▅▃▅▂▂▇▅▄▄▇▆▆▆▇▇█▃▆▄▇</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dobra_cnn-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2pe2ghzy\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2pe2ghzy</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2pe2ghzy). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">down_up_cnn-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/3phq3vre\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/3phq3vre</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225727-3phq3vre</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3phq3vre) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31109<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225727-3phq3vre/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225727-3phq3vre/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02699</td></tr><tr><td>mae</td><td>0.06895</td></tr><tr><td>val_loss</td><td>0.00545</td></tr><tr><td>val_mae</td><td>0.05439</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>89</td></tr><tr><td>_timestamp</td><td>1611529140</td></tr><tr><td>best_val_loss</td><td>0.00544</td></tr><tr><td>best_epoch</td><td>8</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▂▂▃▂▃▃▂▂▁▂▁▂▂▂▂▃▂▂▂▂▂▃▂▃▂▃▂▂▃▃▂▂▂▂▃▃▂▁</td></tr><tr><td>mae</td><td>█▂▂▂▁▂▃▃▁▁▂▂▁▁▂▁▂▂▁▂▂▁▂▂▂▃▂▂▂▃▂▃▁▂▁▁▂▂▃▂</td></tr><tr><td>val_loss</td><td>▂▆▆▅▄▄▄▂▁▄▃▂▄▃▆▁█▂▃▃▂▄▃▃▅▅▆▃▄▄▃▃▄▃▄▆▄▄▁▄</td></tr><tr><td>val_mae</td><td>▂▇▅▅▄▄▄▂▁▄▃▂▄▃▅▁█▂▃▃▂▄▃▃▅▆▆▃▄▄▃▃▄▄▃▆▄▄▂▄</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">down_up_cnn-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/3phq3vre\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/3phq3vre</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3phq3vre). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">by_lstm-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/3r7zbapq\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/3r7zbapq</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225900-3r7zbapq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 11s 91ms/step - loss: 11.3979 - mae: 0.0692 - val_loss: 6.0828 - val_mae: 0.0545\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 5.3034 - mae: 0.0691 - val_loss: 4.5704 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 4.0096 - mae: 0.0690 - val_loss: 3.4298 - val_mae: 0.0545\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 2.9870 - mae: 0.0690 - val_loss: 2.5227 - val_mae: 0.0545\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 2.1805 - mae: 0.0690 - val_loss: 1.8144 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 1.5570 - mae: 0.0690 - val_loss: 1.2733 - val_mae: 0.0545\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 1.0860 - mae: 0.0690 - val_loss: 0.8699 - val_mae: 0.0545\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.7393 - mae: 0.0691 - val_loss: 0.5773 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.4913 - mae: 0.0690 - val_loss: 0.3715 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.3195 - mae: 0.0690 - val_loss: 0.2315 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.2045 - mae: 0.0690 - val_loss: 0.1398 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.1306 - mae: 0.0690 - val_loss: 0.0820 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0849 - mae: 0.0690 - val_loss: 0.0472 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0579 - mae: 0.0690 - val_loss: 0.0271 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0427 - mae: 0.0689 - val_loss: 0.0162 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.0346 - mae: 0.0689 - val_loss: 0.0105 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0305 - mae: 0.0689 - val_loss: 0.0077 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0285 - mae: 0.0689 - val_loss: 0.0064 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0276 - mae: 0.0689 - val_loss: 0.0058 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0272 - mae: 0.0689 - val_loss: 0.0056 - val_mae: 0.0544\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.0271 - mae: 0.0689 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0270 - mae: 0.0689 - val_loss: 0.0054 - val_mae: 0.0544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3r7zbapq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31544<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225900-3r7zbapq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_225900-3r7zbapq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02699</td></tr><tr><td>mae</td><td>0.06895</td></tr><tr><td>val_loss</td><td>0.00544</td></tr><tr><td>val_mae</td><td>0.05436</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>392</td></tr><tr><td>_timestamp</td><td>1611529537</td></tr><tr><td>best_val_loss</td><td>0.00544</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▅▃▃▃▃▃▅▂▂▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>▅▃▆█▇█▆▁▄▄▄▂▂▁▂▂▁▂▂▂▂▁▂▂▂▁▂▁▁▃▅▂▂▂▂▂▄▁▃▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">by_lstm-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/3r7zbapq\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/3r7zbapq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3r7zbapq). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gru-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2zklre7o\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2zklre7o</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_230537-2zklre7o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 20s 166ms/step - loss: 3.8817 - mae: 0.0724 - val_loss: 0.2444 - val_mae: 0.0544\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.1134 - mae: 0.0690 - val_loss: 0.0274 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0364 - mae: 0.0690 - val_loss: 0.0083 - val_mae: 0.0545\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0282 - mae: 0.0691 - val_loss: 0.0058 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0272 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 153ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0270 - mae: 0.0691 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2zklre7o) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32964<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_230537-2zklre7o/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_230537-2zklre7o/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.027</td></tr><tr><td>mae</td><td>0.06897</td></tr><tr><td>val_loss</td><td>0.00545</td></tr><tr><td>val_mae</td><td>0.05443</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>775</td></tr><tr><td>_timestamp</td><td>1611530316</td></tr><tr><td>best_val_loss</td><td>0.00545</td></tr><tr><td>best_epoch</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>▃▃▆▁▄▃█▁▄▅▂▆▇▃▇▃█▅▅▃▄▂▂▇▃▇▄▄▃▁▃▃▂▄▃▂▂▁▁▂</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">gru-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2zklre7o\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2zklre7o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2zklre7o). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">e1d1-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/135aw9az\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/135aw9az</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_231836-135aw9az</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 6s 53ms/step - loss: 0.0267 - mae: 0.0697 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 6s 47ms/step - loss: 0.0264 - mae: 0.0693 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0264 - mae: 0.0693 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0261 - mae: 0.0697 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0264 - mae: 0.0695 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0268 - mae: 0.0695 - val_loss: 0.0054 - val_mae: 0.0546\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0259 - mae: 0.0697 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0254 - mae: 0.0700 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0243 - mae: 0.0698 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0226 - mae: 0.0692 - val_loss: 0.0057 - val_mae: 0.0555\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0227 - mae: 0.0699 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0208 - mae: 0.0696 - val_loss: 0.0081 - val_mae: 0.0653\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0229 - mae: 0.0696 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0221 - mae: 0.0693 - val_loss: 0.0060 - val_mae: 0.0576\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0214 - mae: 0.0688 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0207 - mae: 0.0697 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0207 - mae: 0.0683 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0215 - mae: 0.0687 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0220 - mae: 0.0685 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0215 - mae: 0.0682 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0210 - mae: 0.0681 - val_loss: 0.0056 - val_mae: 0.0550\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0211 - mae: 0.0683 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0196 - mae: 0.0677 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0191 - mae: 0.0676 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0190 - mae: 0.0674 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0189 - mae: 0.0674 - val_loss: 0.0053 - val_mae: 0.0536\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0189 - mae: 0.0673 - val_loss: 0.0053 - val_mae: 0.0538\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0189 - mae: 0.0673 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0189 - mae: 0.0673 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0188 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0188 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0187 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0188 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0187 - mae: 0.0671 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0186 - mae: 0.0670 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0354 - mae: 0.0919 - val_loss: 0.0078 - val_mae: 0.0677\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0275 - mae: 0.0707 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0270 - mae: 0.0692 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0270 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0269 - mae: 0.0690 - val_loss: 0.0055 - val_mae: 0.0546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:135aw9az) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35522<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_231836-135aw9az/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_231836-135aw9az/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02694</td></tr><tr><td>mae</td><td>0.06895</td></tr><tr><td>val_loss</td><td>0.00548</td></tr><tr><td>val_mae</td><td>0.05464</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>246</td></tr><tr><td>_timestamp</td><td>1611530566</td></tr><tr><td>best_val_loss</td><td>0.0053</td></tr><tr><td>best_epoch</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▄▄▄▄▄▄▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▅▅▄</td></tr><tr><td>mae</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂▂▂▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▂▂▁█▂▃▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁</td></tr><tr><td>val_mae</td><td>▁▁▁▁▁▁▁▂▂▂▂▇▂▃▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▂</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">e1d1-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/135aw9az\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/135aw9az</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:135aw9az). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dense-30m-item5610</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2gvwuun9\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2gvwuun9</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232246-2gvwuun9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0698 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.0257 - mae: 0.0697 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.0244 - mae: 0.0690 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.0227 - mae: 0.0688 - val_loss: 0.0054 - val_mae: 0.0543\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.0215 - mae: 0.0683 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.0681 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.0213 - mae: 0.0680 - val_loss: 0.0053 - val_mae: 0.0535\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0205 - mae: 0.0682 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0679 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0680 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0206 - mae: 0.0674 - val_loss: 0.0053 - val_mae: 0.0536\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0673 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0672 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0673 - val_loss: 0.0056 - val_mae: 0.0551\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0677 - val_loss: 0.0056 - val_mae: 0.0550\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0681 - val_loss: 0.0058 - val_mae: 0.0557\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0678 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0676 - val_loss: 0.0055 - val_mae: 0.0545\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0670 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0148 - mae: 0.0667 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.0150 - mae: 0.0667 - val_loss: 0.0058 - val_mae: 0.0554\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0660 - val_loss: 0.0057 - val_mae: 0.0556\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0655 - val_loss: 0.0056 - val_mae: 0.0554\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0649 - val_loss: 0.0056 - val_mae: 0.0554\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0644 - val_loss: 0.0058 - val_mae: 0.0562\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0641 - val_loss: 0.0056 - val_mae: 0.0555\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0640 - val_loss: 0.0056 - val_mae: 0.0557\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0634 - val_loss: 0.0058 - val_mae: 0.0561\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0625 - val_loss: 0.0058 - val_mae: 0.0567\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0624 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0616 - val_loss: 0.0058 - val_mae: 0.0568\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0612 - val_loss: 0.0062 - val_mae: 0.0583\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0602 - val_loss: 0.0060 - val_mae: 0.0572\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0595 - val_loss: 0.0062 - val_mae: 0.0586\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0588 - val_loss: 0.0064 - val_mae: 0.0589\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0579 - val_loss: 0.0067 - val_mae: 0.0607\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0602 - val_loss: 0.0068 - val_mae: 0.0607\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0584 - val_loss: 0.0068 - val_mae: 0.0600\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0573 - val_loss: 0.0067 - val_mae: 0.0611\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0555 - val_loss: 0.0068 - val_mae: 0.0607\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2gvwuun9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36441<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232246-2gvwuun9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232246-2gvwuun9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.00683</td></tr><tr><td>mae</td><td>0.05549</td></tr><tr><td>val_loss</td><td>0.0068</td></tr><tr><td>val_mae</td><td>0.06069</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>25</td></tr><tr><td>_timestamp</td><td>1611530595</td></tr><tr><td>best_val_loss</td><td>0.00533</td></tr><tr><td>best_epoch</td><td>6</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>██▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▃▂▁▁</td></tr><tr><td>mae</td><td>████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▃▂▂▁</td></tr><tr><td>val_loss</td><td>▂▂▁▂▁▁▁▁▁▁▁▂▁▂▂▃▂▂▂▂▃▃▂▂▃▂▂▃▃▄▃▅▄▅▆▇████</td></tr><tr><td>val_mae</td><td>▂▂▂▂▁▁▁▁▁▁▁▂▁▂▂▃▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▄▆▆██▇██</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dense-30m-item5610</strong>: <a href=\"https://wandb.ai/kriza/30m-item56/runs/2gvwuun9\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/2gvwuun9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2gvwuun9). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lstm-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/3cf65xyb\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/3cf65xyb</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232316-3cf65xyb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 20s 167ms/step - loss: 0.0158 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0453\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0161 - mae: 0.0563 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0158 - mae: 0.0559 - val_loss: 0.0032 - val_mae: 0.0446\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0159 - mae: 0.0558 - val_loss: 0.0032 - val_mae: 0.0441\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0158 - mae: 0.0557 - val_loss: 0.0032 - val_mae: 0.0442\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0157 - mae: 0.0556 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0555 - val_loss: 0.0034 - val_mae: 0.0457\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0555 - val_loss: 0.0033 - val_mae: 0.0446\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0158 - mae: 0.0557 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0556 - val_loss: 0.0032 - val_mae: 0.0448\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0554 - val_loss: 0.0032 - val_mae: 0.0444\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0156 - mae: 0.0554 - val_loss: 0.0032 - val_mae: 0.0440\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0555 - val_loss: 0.0032 - val_mae: 0.0444\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0554 - val_loss: 0.0032 - val_mae: 0.0447\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0156 - mae: 0.0554 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0522 - mae: 0.0802 - val_loss: 0.0034 - val_mae: 0.0455\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0243 - mae: 0.0582 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0578 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0283 - mae: 0.0704 - val_loss: 0.0034 - val_mae: 0.0456\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0242 - mae: 0.0578 - val_loss: 0.0034 - val_mae: 0.0455\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0577 - val_loss: 0.0034 - val_mae: 0.0456\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0242 - mae: 0.0575 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0577 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0238 - mae: 0.0582 - val_loss: 0.0034 - val_mae: 0.0457\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0232 - mae: 0.0587 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0231 - mae: 0.0585 - val_loss: 0.0033 - val_mae: 0.0453\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0231 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0239 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0217 - mae: 0.0572 - val_loss: 0.0034 - val_mae: 0.0456\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0220 - mae: 0.0579 - val_loss: 0.0033 - val_mae: 0.0453\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0242 - mae: 0.0575 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0574 - val_loss: 0.0034 - val_mae: 0.0454\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0575 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0241 - mae: 0.0574 - val_loss: 0.0034 - val_mae: 0.0455\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0240 - mae: 0.0576 - val_loss: 0.0034 - val_mae: 0.0454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3cf65xyb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36698<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232316-3cf65xyb/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_232316-3cf65xyb/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02404</td></tr><tr><td>mae</td><td>0.05759</td></tr><tr><td>val_loss</td><td>0.00336</td></tr><tr><td>val_mae</td><td>0.04535</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>773</td></tr><tr><td>_timestamp</td><td>1611531373</td></tr><tr><td>best_val_loss</td><td>0.00316</td></tr><tr><td>best_epoch</td><td>12</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▃▃▃▃▃▃▃▂▂▂▃▂▂▃▃▃▃▃▃▃▃▃</td></tr><tr><td>mae</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂▂▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_loss</td><td>▃▃▂▂▁▁▂▃▂▃▂▁▁▂▂▃▃▄▃▃▃▃▃▄▃█▃▃▃▃▃▂▃▃▃▃▃▃▃▃</td></tr><tr><td>val_mae</td><td>▃▃▂▂▁▁▂▃▂▄▂▂▁▂▂▄▃▄▄▃▃▃▃▄▃█▃▃▃▃▃▂▂▃▃▃▃▃▃▃</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lstm-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/3cf65xyb\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/3cf65xyb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3cf65xyb). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cnn-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/2ruz64lw\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/2ruz64lw</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233613-2ruz64lw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ruz64lw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39226<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233613-2ruz64lw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233613-2ruz64lw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02418</td></tr><tr><td>mae</td><td>0.05721</td></tr><tr><td>val_loss</td><td>0.00331</td></tr><tr><td>val_mae</td><td>0.0449</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>118</td></tr><tr><td>_timestamp</td><td>1611531497</td></tr><tr><td>best_val_loss</td><td>0.00331</td></tr><tr><td>best_epoch</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▃▄▂▄▃▁▁▄▃▅▄▂▆▃▂▄▃▃▄▃▃▅▃█▂▆▃▄▆▄▆▄▄▆▆▃▃▄▅▆</td></tr><tr><td>mae</td><td>▃▃▃▆▄▃▂▃▁▃▅▃▆▃▃▃▃▄▅▄▃▆▄█▄▄▄▃▅▅▄▃▃▅▃▅▇▂▃▄</td></tr><tr><td>val_loss</td><td>▂▁▃▄▆▆▇▂▆▃▄█▆▁▅▆▃▇▃▆▅█▆▅▇▄█▇▅▅▃▇▄▃▄▃▆▂▂▄</td></tr><tr><td>val_mae</td><td>▂▁▃▄▆▆█▂▆▃▄▇▆▁▄▆▃▇▂▆▅█▆▆▇▄▇▇▆▆▃▇▄▃▅▃▆▂▂▅</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cnn-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/2ruz64lw\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/2ruz64lw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2ruz64lw). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dobra_cnn-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/1867fx7q\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/1867fx7q</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233817-1867fx7q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.0162 - mae: 0.0562 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0161 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0161 - mae: 0.0561 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0161 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0157 - mae: 0.0557 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0034 - val_mae: 0.0452\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.0158 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0157 - mae: 0.0558 - val_loss: 0.0034 - val_mae: 0.0453\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.0558 - val_loss: 0.0034 - val_mae: 0.0452\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.0557 - val_loss: 0.0034 - val_mae: 0.0453\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.0557 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.0557 - val_loss: 0.0034 - val_mae: 0.0453\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.0557 - val_loss: 0.0034 - val_mae: 0.0453\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0154 - mae: 0.0557 - val_loss: 0.0034 - val_mae: 0.0452\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.0558 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0561 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1867fx7q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39758<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233817-1867fx7q/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233817-1867fx7q/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.0156</td></tr><tr><td>mae</td><td>0.05594</td></tr><tr><td>val_loss</td><td>0.00334</td></tr><tr><td>val_mae</td><td>0.04508</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>54</td></tr><tr><td>_timestamp</td><td>1611531555</td></tr><tr><td>best_val_loss</td><td>0.00331</td></tr><tr><td>best_epoch</td><td>18</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▆▆▆▆▅▇▇▅▆▆▇▅▅▄▅▅▄▅▅▄▃▄▄▄▄▄▆▄▃▃▃▂▁▁▁▂▄▂</td></tr><tr><td>mae</td><td>█▆▆▅▅▅▃▅▆▄▄▄▆▄▃▂▄▃▃▃▃▃▁▂▂▂▃▄▅▃▂▂▂▂▁▂▁▂▆▄</td></tr><tr><td>val_loss</td><td>▁▂▂▂▄▃▃▃▂▁▂▄▂▂▂▂▃▂▁▃▃▄▄▃▄▆▄▂▁▇▆▄▇▄█▆▅▄▃▄</td></tr><tr><td>val_mae</td><td>▁▂▃▃▅▃▃▃▃▂▃▄▂▂▃▂▄▃▁▄▄▆▅▄▄▇▅▂▂█▆▄█▄▇█▆▄▄▄</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dobra_cnn-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/1867fx7q\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/1867fx7q</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1867fx7q). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">down_up_cnn-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/1yi78cgd\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/1yi78cgd</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233915-1yi78cgd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1yi78cgd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40098<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233915-1yi78cgd/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_233915-1yi78cgd/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02418</td></tr><tr><td>mae</td><td>0.05719</td></tr><tr><td>val_loss</td><td>0.00331</td></tr><tr><td>val_mae</td><td>0.04491</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>88</td></tr><tr><td>_timestamp</td><td>1611531647</td></tr><tr><td>best_val_loss</td><td>0.00331</td></tr><tr><td>best_epoch</td><td>6</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▃▂▃▃▁▂▂▂▂▂█▁▂▂▂▃▂▃▂▂▁▂</td></tr><tr><td>mae</td><td>▂▃▁▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▃▂▂▂▂▁█▂▁▂▂▃▂▂▂▂▂▂</td></tr><tr><td>val_loss</td><td>█▃▂▃▂▇▂▄▃▄▂▃▃▄▂▄▅▅▅▅▄▄▅▃▂▅▁▄▃▄▃▄▅▃▃▂▄▂▄▄</td></tr><tr><td>val_mae</td><td>█▂▃▄▁▇▂▅▂▄▂▃▃▄▂▅▅▅▅▅▄▄▅▃▂▆▁▄▃▄▃▄▅▃▃▂▄▂▄▄</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">down_up_cnn-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/1yi78cgd\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/1yi78cgd</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1yi78cgd). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">by_lstm-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/2bguhuu3\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/2bguhuu3</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234047-2bguhuu3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 11s 91ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2bguhuu3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40538<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234047-2bguhuu3/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234047-2bguhuu3/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02418</td></tr><tr><td>mae</td><td>0.0572</td></tr><tr><td>val_loss</td><td>0.00332</td></tr><tr><td>val_mae</td><td>0.04491</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>392</td></tr><tr><td>_timestamp</td><td>1611532043</td></tr><tr><td>best_val_loss</td><td>0.00331</td></tr><tr><td>best_epoch</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▂▁▂▁▂▂▂▂▂▁▂▁▂▂█▂▂▂▁▂▂▁▂▂▁▁▁▁▂▂▂▂▆▂▂▁▂▂▂▁</td></tr><tr><td>mae</td><td>▂▂▂▂▃▂▂▃▂▂▂▃▂▂█▃▃▃▂▁▂▁▂▁▁▁▁▂▂▂▂▁█▄▃▂▂▂▃▂</td></tr><tr><td>val_loss</td><td>▂▁▄▅▅▂▃▄▃▃▃▃▃█▂▄▃▁▃▂▂▂▂▁▂▂▂▂▃▄▂▅▃▅▂▃▂▃▂▂</td></tr><tr><td>val_mae</td><td>▄▂▇▆▆▂▂▆▅▂▅▇▃▇▃▇▄▂▅▂▄▄▃▁▂▃▂▂▄▄▂▄▃█▂▄▃▅▂▄</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">by_lstm-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/2bguhuu3\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/2bguhuu3</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2bguhuu3). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gru-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/12gi2t5q\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/12gi2t5q</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234723-12gi2t5q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 20s 165ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0034 - val_mae: 0.0450\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 159ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - ETA: 0s - loss: 0.0242 - mae: 0.057 - 19s 156ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 19s 153ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 18s 152ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 19s 156ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 19s 153ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 19s 157ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 19s 158ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 18s 153ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 19s 155ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 18s 149ms/step - loss: 0.0242 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:12gi2t5q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1386<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234723-12gi2t5q/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/richard_stana/programing/clanok/code/wandb/run-20210124_234723-12gi2t5q/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02419</td></tr><tr><td>mae</td><td>0.05722</td></tr><tr><td>val_loss</td><td>0.00332</td></tr><tr><td>val_mae</td><td>0.04489</td></tr><tr><td>_step</td><td>39</td></tr><tr><td>_runtime</td><td>765</td></tr><tr><td>_timestamp</td><td>1611532814</td></tr><tr><td>best_val_loss</td><td>0.00331</td></tr><tr><td>best_epoch</td><td>13</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▄█▂▂▅▂▄▄▁▃▂▃▃▂▁▂▃▃▃▂▂▃▂▂▂▂▃▃▂▂▃▃▃▆▃▂▂▂▄▃</td></tr><tr><td>mae</td><td>█▅▄▃▇▃▂▂▃▅▄▂▃▂▁▁▂▃▃▁▂▂▂▂▁▁▃▂▂▂▂▂▃▆▂▂▃▃▃▃</td></tr><tr><td>val_loss</td><td>█▂▂▃▂▂▂▁▂▂▂▂▁▁▁▂▃▂▁▂▂▁▂▂▂▂▂▂▂▂▁▂▃▂▂▂▂▃▂▂</td></tr><tr><td>val_mae</td><td>▇▄▃█▃▄▃▄▃▄▅▄▁▁▂▄▇▄▁▃▃▂▃▄▃▄▅▃▄▄▂▃▃▃▃▅▂█▄▃</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">gru-30m-item5710</strong>: <a href=\"https://wandb.ai/kriza/30m-item57/runs/12gi2t5q\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/12gi2t5q</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:12gi2t5q). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">e1d1-30m-item5710</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item57\" target=\"_blank\">https://wandb.ai/kriza/30m-item57</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item57/runs/2r82x62b\" target=\"_blank\">https://wandb.ai/kriza/30m-item57/runs/2r82x62b</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210125_000014-2r82x62b</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 6s 54ms/step - loss: 0.0255 - mae: 0.0619 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0242 - mae: 0.0574 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0450A: 0s - loss: 0.0250 \n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0242 - mae: 0.0573 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0241 - mae: 0.0575 - val_loss: 0.0034 - val_mae: 0.0456\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0241 - mae: 0.0578 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0240 - mae: 0.0581 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0236 - mae: 0.0578 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0241 - mae: 0.0616 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0241 - mae: 0.0588 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0239 - mae: 0.0586 - val_loss: 0.0049 - val_mae: 0.0566- loss: 0.0243 - mae\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0240 - mae: 0.0581 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.0236 - mae: 0.0577 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0232 - mae: 0.0579 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0222 - mae: 0.0582 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0200 - mae: 0.0572 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0194 - mae: 0.0571 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0180 - mae: 0.0565 - val_loss: 0.0034 - val_mae: 0.0454\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0176 - mae: 0.0563 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0175 - mae: 0.0566 - val_loss: 0.0033 - val_mae: 0.0447\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0174 - mae: 0.0569 - val_loss: 0.0033 - val_mae: 0.0446\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0173 - mae: 0.0566 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0166 - mae: 0.0563 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0161 - mae: 0.0559 - val_loss: 0.0033 - val_mae: 0.0445\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0162 - mae: 0.0561 - val_loss: 0.0033 - val_mae: 0.0446\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0172 - mae: 0.0567 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0175 - mae: 0.0561 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0173 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0172 - mae: 0.0560 - val_loss: 0.0032 - val_mae: 0.0445\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0171 - mae: 0.0561 - val_loss: 0.0032 - val_mae: 0.0445: 0s - loss: 0.0172 - mae: 0.0 - ETA: 0s - loss: 0.0170 - mae:\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0168 - mae: 0.0560 - val_loss: 0.0033 - val_mae: 0.0451\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0165 - mae: 0.0559 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0163 - mae: 0.0561 - val_loss: 0.0032 - val_mae: 0.0443\n",
      "Epoch 14/20\n",
      "  7/121 [>.............................] - ETA: 4s - loss: 0.0169 - mae: 0.0569"
     ]
    }
   ],
   "source": [
    "for i in items:\n",
    "    actual_item = i\n",
    "    train_x, train_y = predspracovanie.create_x_y(train_df[actual_item], n_inputs, n_outputs)\n",
    "    train_x1, train_y1 = predspracovanie.create_x_y(train1_df[actual_item], n_inputs, n_outputs)\n",
    "    val_x, val_y = predspracovanie.create_x_y(val_df[actual_item], n_inputs, n_outputs)\n",
    "\n",
    "    compile_and_fit(actual_item, model_lstm, \"lstm-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_cnn, \"cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, dobra_model_cnn, \"dobra_cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "\n",
    "    compile_and_fit(actual_item, down_up_model_cnn, \"down_up_cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, by_lstm_model, \"by_lstm-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, gru_model, \"gru-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_e1d1, \"e1d1-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_dense, \"dense-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipTF2.3-gpu",
   "language": "python",
   "name": "piptf2.3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
