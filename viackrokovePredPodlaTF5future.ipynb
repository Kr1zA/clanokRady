{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7448976527568966066\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9400944972637878405\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2184733191477737828\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7779456128\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11491398783758922116\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import predspracovanie\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pickle\n",
    "\n",
    "import copy\n",
    "\n",
    "import tensorflow.keras.backend as backend\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"GPU\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [\n",
    "    '30m-item56', \n",
    "         '30m-item57', '30m-item58', '30m-item59', '30m-item61', '30m-item62', '30m-item66', '30m-item67', '30m-item69', '30m-item71', '30m-item72', '30m-item73', '30m-item75',\n",
    "    '30m-item76', \n",
    "    '30m-item77'\n",
    "        ]\n",
    "df = pickle.load( open( \"/home/richard_stana/programing/clanok/data/picklnute/30min.p\", \"rb\" ) )\n",
    "# df = predspracovanie.make_dataset(df)\n",
    "df = df.drop([\"30m-item60\", \"30m-item63\", \"30m-item64\", \"30m-item65\", \"30m-item68\", \"30m-item70\", \"30m-item74\"], axis=1)\n",
    "# df = df[actual_item]\n",
    "# predspracovanie.draw(df, datum_alebo_cisla=\"cislo\", y1_orig=df[actual_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = df[76:44000]\n",
    "# val_df = df[44001:46655]\n",
    "# test_df = df[46800:52389]\n",
    "train_df = df[27:15549]\n",
    "train1_df = df[15602:17160]\n",
    "val_df = df[17160-144-1:17460]\n",
    "# test_df = df[46800:52389]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_orig = train_df.copy()\n",
    "train_df = predspracovanie.create_log_difference(train_df)\n",
    "train1_df_orig = train1_df.copy()\n",
    "train1_df = predspracovanie.create_log_difference(train1_df)\n",
    "val_df_orig = val_df.copy()\n",
    "val_df = predspracovanie.create_log_difference(val_df)\n",
    "# test_df_orig = test_df.copy()\n",
    "# test_df = predspracovanie.create_log_difference(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 144\n",
    "n_outputs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(projekt, model, nazov_modelu, train_x, train_y, train_x1, train_y1, val_x, val_y, compile=False, epochs=200):\n",
    "    wandb.init(project=projekt, name=nazov_modelu + str(n_outputs))\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models_clanok/\" + nazov_modelu + \"future\" + str(n_outputs) + \".hdf5\",\n",
    "        #     save_weights_only=True,\n",
    "        monitor='val_mae',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "    model_checkpoint_callback1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models_clanok/\" + nazov_modelu + \"future\" + str(n_outputs) + \"1.hdf5\",\n",
    "        #     save_weights_only=True,\n",
    "        monitor='val_mae',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    if compile:\n",
    "        model.compile(loss='mse',\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics='mae')\n",
    "\n",
    "    history = model.fit(x=np.array(train_x).reshape((-1,n_inputs,1)),\n",
    "                      y=np.array(train_y).reshape((-1,n_outputs)),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(np.array(val_x).reshape((-1,n_inputs,1)), np.array(val_y).reshape((-1,n_outputs))),\n",
    "                      batch_size=128,\n",
    "                      callbacks=[model_checkpoint_callback, \n",
    "                                     WandbCallback()\n",
    "                                ])\n",
    "    history = model.fit(x=np.array(train_x).reshape((-1,n_inputs,1)),\n",
    "                      y=np.array(train_y).reshape((-1,n_outputs)),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(np.array(val_x).reshape((-1,n_inputs,1)), np.array(val_y).reshape((-1,n_outputs))),\n",
    "                      batch_size=128,\n",
    "                      callbacks=[model_checkpoint_callback1, \n",
    "                                     WandbCallback()\n",
    "                                ])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"lstm_input\"\n",
    ")  \n",
    "lstm = layers.LSTM(512, return_sequences=True)(lstm_input)\n",
    "lstm = layers.LSTM(512, return_sequences=True)(lstm)\n",
    "lstm = layers.LSTM(512, return_sequences=False)(lstm)\n",
    "lstm_output = layers.Dense(units=n_outputs)(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = keras.Model(\n",
    "    inputs=[lstm_input],\n",
    "    outputs=[lstm_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"cnn_input\"\n",
    ")  \n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn_input)\n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn)\n",
    "cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(cnn)\n",
    "flat = layers.Flatten()(cnn)\n",
    "dense = layers.Dense(units=64, activation='relu')(flat)\n",
    "cnn_output = layers.Dense(units=n_outputs)(dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.Model(\n",
    "    inputs=[cnn_input],\n",
    "    outputs=[cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobra_cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"dobra_cnn_input\"\n",
    ")  \n",
    "dobra_cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn_input)\n",
    "dobra_cnn = layers.Conv1D(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn)\n",
    "dobra_cnn = layers.Conv1D(filters=64,\n",
    "                           kernel_size=(3,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(dobra_cnn)\n",
    "dobra_flat = layers.Flatten()(dobra_cnn)\n",
    "dobra_dense = layers.Dense(units=64, activation='relu')(dobra_flat)\n",
    "dobra_cnn_output = layers.Dense(units=n_outputs)(dobra_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobra_model_cnn = keras.Model(\n",
    "    inputs=[dobra_cnn_input],\n",
    "    outputs=[dobra_cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dobra_cnn_input (InputLayer) [(None, 144, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 144, 256)          2048      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 144, 128)          163968    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 144, 64)           24640     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 780,869\n",
      "Trainable params: 780,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dobra_model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_up_cnn_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"down_up_cnn_input\"\n",
    ")  \n",
    "down_up_cnn = layers.Conv1D(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn_input)\n",
    "down_up_cnn = layers.Conv1D(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn)\n",
    "down_up_flat = layers.Flatten()(down_up_cnn)\n",
    "down_up_dense = layers.Dense(units=1, activation='sigmoid')(down_up_flat)\n",
    "down_up_dense = layers.Dense(units=144*64, input_dim=128)(down_up_dense)\n",
    "down_up_reshape = layers.Reshape((144, 64))(down_up_dense)\n",
    "down_up_cnn = layers.Conv1DTranspose(filters=128,\n",
    "                           kernel_size=(5,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_reshape)\n",
    "down_up_cnn = layers.Conv1DTranspose(filters=256,\n",
    "                           kernel_size=(7,),\n",
    "                           activation='relu',\n",
    "                           padding=\"same\")(down_up_cnn)\n",
    "down_up_flat = layers.Flatten()(down_up_cnn)\n",
    "# down_up_dense = layers.Dense(units=64, activation='relu')(down_up_flat)\n",
    "down_up_cnn_output = layers.Dense(units=n_outputs)(down_up_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_up_model_cnn = keras.Model(\n",
    "    inputs=[down_up_cnn_input],\n",
    "    outputs=[down_up_cnn_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "down_up_cnn_input (InputLaye [(None, 144, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 144, 256)          2048      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 144, 128)          163968    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 18433     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9216)              18432     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 144, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 144, 128)          41088     \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 144, 256)          229632    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 184325    \n",
      "=================================================================\n",
      "Total params: 657,926\n",
      "Trainable params: 657,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "down_up_model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lstm_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"lstm_input\"\n",
    ")  \n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm_input)\n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm)\n",
    "by_lstm = layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(by_lstm)\n",
    "by_lstm_output = layers.Dense(units=n_outputs)(by_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lstm_model = keras.Model(\n",
    "    inputs=[by_lstm_input],\n",
    "    outputs=[by_lstm_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_input = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"gru_input\"\n",
    ")  \n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru_input)\n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "gru = layers.GRU(256, return_sequences=True, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "simpleRRN = tf.keras.layers.SimpleRNN(128, dropout=0.75, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))(gru)\n",
    "gru_output = layers.Dense(units=n_outputs)(simpleRRN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = keras.Model(\n",
    "    inputs=[gru_input],\n",
    "    outputs=[gru_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(\n",
    "    shape=(n_inputs, 1), name=\"encoder_inputs\"\n",
    ")  \n",
    "encoder_l1 = layers.LSTM(512, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "decoder_inputs = layers.RepeatVector(n_outputs)(encoder_outputs1[0])\n",
    "decoder_l1 = layers.LSTM(512, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = layers.TimeDistributed(layers.Dense(1))(decoder_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 144, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 512), (None, 1052672     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 5, 512)       0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 5, 512)       2099200     repeat_vector[0][0]              \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 5, 1)         513         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,152,385\n",
      "Trainable params: 3,152,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_e1d1 = keras.Model(\n",
    "    inputs=[encoder_inputs],\n",
    "    outputs=[decoder_outputs1]\n",
    ")\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_input = keras.Input(\n",
    "    shape=(n_inputs), name=\"dense_input\"\n",
    ")  \n",
    "dense = layers.Dense(units=1024, activation='relu')(dense_input)\n",
    "dense = layers.Dense(units=512, activation='relu')(dense)\n",
    "dense = layers.Dense(units=256, activation='relu')(dense)\n",
    "dense = layers.Dense(units=128, activation='relu')(dense)\n",
    "dense_output = layers.Dense(units=n_outputs)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_input (InputLayer)     [(None, 144)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              148480    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 838,149\n",
      "Trainable params: 838,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense = keras.Model(\n",
    "    inputs=[dense_input],\n",
    "    outputs=[dense_output]\n",
    ")\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkriza\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lstm-30m-item565</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kriza/30m-item56\" target=\"_blank\">https://wandb.ai/kriza/30m-item56</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kriza/30m-item56/runs/1to8kwa9\" target=\"_blank\">https://wandb.ai/kriza/30m-item56/runs/1to8kwa9</a><br/>\n",
       "                Run data is saved locally in <code>/home/richard_stana/programing/clanok/code/wandb/run-20210126_135853-1to8kwa9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "121/121 [==============================] - 19s 154ms/step - loss: 0.0268 - mae: 0.0698 - val_loss: 0.0063 - val_mae: 0.0563\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 18s 148ms/step - loss: 0.0262 - mae: 0.0701 - val_loss: 0.0060 - val_mae: 0.0550\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 18s 146ms/step - loss: 0.0254 - mae: 0.0705 - val_loss: 0.0061 - val_mae: 0.0552\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 18s 147ms/step - loss: 0.0262 - mae: 0.0700 - val_loss: 0.0063 - val_mae: 0.0569\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 18s 147ms/step - loss: 0.0260 - mae: 0.0720 - val_loss: 0.0061 - val_mae: 0.0555\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 18s 148ms/step - loss: 0.0233 - mae: 0.0718 - val_loss: 0.0063 - val_mae: 0.0567\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 18s 148ms/step - loss: 0.0188 - mae: 0.0735 - val_loss: 0.0090 - val_mae: 0.0721\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 18s 149ms/step - loss: 0.0178 - mae: 0.0701 - val_loss: 0.0140 - val_mae: 0.0922\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 18s 149ms/step - loss: 0.0302 - mae: 0.0738 - val_loss: 0.0063 - val_mae: 0.0563\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 18s 149ms/step - loss: 0.0272 - mae: 0.0703 - val_loss: 0.0062 - val_mae: 0.0558\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0271 - mae: 0.0697 - val_loss: 0.0061 - val_mae: 0.0555\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0270 - mae: 0.0692 - val_loss: 0.0061 - val_mae: 0.0555\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0270 - mae: 0.0702 - val_loss: 0.0067 - val_mae: 0.0584\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0269 - mae: 0.0710 - val_loss: 0.0063 - val_mae: 0.0558\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0259 - mae: 0.0730 - val_loss: 0.0063 - val_mae: 0.0562\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0270 - mae: 0.0703 - val_loss: 0.0063 - val_mae: 0.0561\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0241 - mae: 0.0725 - val_loss: 0.0061 - val_mae: 0.0552\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0235 - mae: 0.0743 - val_loss: 0.0084 - val_mae: 0.0681\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0203 - mae: 0.0727 - val_loss: 0.0064 - val_mae: 0.0566\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0190 - mae: 0.0713 - val_loss: 0.0062 - val_mae: 0.0558\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 18s 152ms/step - loss: 0.0157 - mae: 0.0682 - val_loss: 0.0061 - val_mae: 0.0552\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0145 - mae: 0.0677 - val_loss: 0.0061 - val_mae: 0.0553\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 18s 151ms/step - loss: 0.0142 - mae: 0.0674 - val_loss: 0.0061 - val_mae: 0.0553\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 18s 153ms/step - loss: 0.0141 - mae: 0.0672 - val_loss: 0.0060 - val_mae: 0.0550\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 18s 153ms/step - loss: 0.0138 - mae: 0.0670 - val_loss: 0.0060 - val_mae: 0.0547\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 19s 153ms/step - loss: 0.0137 - mae: 0.0668 - val_loss: 0.0060 - val_mae: 0.0547\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 18s 150ms/step - loss: 0.0136 - mae: 0.0667 - val_loss: 0.0061 - val_mae: 0.0553\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 18s 151ms/step - loss: 0.0136 - mae: 0.0671 - val_loss: 0.0061 - val_mae: 0.0555\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 18s 151ms/step - loss: 0.0134 - mae: 0.0663 - val_loss: 0.0061 - val_mae: 0.0554\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 18s 152ms/step - loss: 0.0133 - mae: 0.0663 - val_loss: 0.0060 - val_mae: 0.0547\n",
      "Epoch 11/20\n",
      " 75/121 [=================>............] - ETA: 6s - loss: 0.0129 - mae: 0.0662"
     ]
    }
   ],
   "source": [
    "for i in items:\n",
    "    actual_item = i\n",
    "    train_x, train_y = predspracovanie.create_x_y(train_df[actual_item], n_inputs, n_outputs)\n",
    "    train_x1, train_y1 = predspracovanie.create_x_y(train1_df[actual_item], n_inputs, n_outputs)\n",
    "    val_x, val_y = predspracovanie.create_x_y(val_df[actual_item], n_inputs, n_outputs)\n",
    "\n",
    "    compile_and_fit(actual_item, model_lstm, \"lstm-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_cnn, \"cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, dobra_model_cnn, \"dobra_cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "\n",
    "    compile_and_fit(actual_item, down_up_model_cnn, \"down_up_cnn-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, by_lstm_model, \"by_lstm-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, gru_model, \"gru-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_e1d1, \"e1d1-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n",
    "    compile_and_fit(actual_item, model_dense, \"dense-\" + actual_item, train_x = train_x, train_y = train_y, train_x1 = train_x1, train_y1 = train_y1, val_x = val_x, val_y = val_y, compile=True, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipTF2.3-gpu",
   "language": "python",
   "name": "piptf2.3-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
